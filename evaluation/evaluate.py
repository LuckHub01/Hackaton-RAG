"""
SYSTÃˆME D'Ã‰VALUATION - Culture BurkinabÃ¨ RAG
Ã‰valuation automatique avec 20 questions test
"""

import json
import time
from typing import List, Dict
import numpy as np
from datetime import datetime
import sys

sys.path.append('.')
from src.rag_pipeline import CultureRAGPipeline


class RAGEvaluator:
    """Ã‰valuateur pour le systÃ¨me RAG"""
    
    def __init__(self, rag_pipeline: CultureRAGPipeline, test_file: str):
        """
        Args:
            rag_pipeline: Pipeline RAG Ã  Ã©valuer
            test_file: Fichier JSON avec questions test
        """
        self.rag = rag_pipeline
        self.test_file = test_file
        self.results = []
    
    def calculate_retrieval_precision(self, retrieved_docs: List[Dict], expected_keywords: List[str]) -> float:
        """
        Calcul de la prÃ©cision du retrieval
        
        Args:
            retrieved_docs: Documents rÃ©cupÃ©rÃ©s
            expected_keywords: Mots-clÃ©s attendus dans les documents pertinents
        
        Returns:
            Score de prÃ©cision entre 0 et 1
        """
        if not expected_keywords or not retrieved_docs:
            return 0.0
        
        # Compter combien de documents contiennent au moins un mot-clÃ©
        relevant_docs = 0
        
        for doc in retrieved_docs:
            content = f"{doc['title']} {doc['content']}".lower()
            if any(keyword.lower() in content for keyword in expected_keywords):
                relevant_docs += 1
        
        return relevant_docs / len(retrieved_docs)
    
    def calculate_answer_relevance(self, answer: str, expected_answer: str, question: str) -> float:
        """
        Ã‰valuation de la pertinence de la rÃ©ponse (score /5)
        
        CritÃ¨res:
        - Contient les informations attendues (2 pts)
        - RÃ©pond directement Ã  la question (1 pt)
        - Structure claire (1 pt)
        - Sources mentionnÃ©es (1 pt)
        """
        score = 0.0
        answer_lower = answer.lower()
        expected_lower = expected_answer.lower()
        
        # 1. Contenu attendu (2 pts)
        expected_words = set(expected_lower.split())
        answer_words = set(answer_lower.split())
        
        # Calculer l'intersection
        common_words = expected_words & answer_words
        content_score = min(2.0, (len(common_words) / max(len(expected_words), 1)) * 2)
        score += content_score
        
        # 2. RÃ©pond Ã  la question (1 pt)
        question_words = set(question.lower().split())
        question_overlap = len(question_words & answer_words)
        if question_overlap >= 2:
            score += 1.0
        elif question_overlap >= 1:
            score += 0.5
        
        # 3. Structure (1 pt)
        if len(answer) > 50 and not answer.startswith("Je n'ai pas"):
            score += 0.5
        if any(char in answer for char in ['.', ',', ';']):  # Ponctuation
            score += 0.5
        
        # 4. Sources mentionnÃ©es (1 pt)
        source_indicators = ['selon', 'article', 'source', 'd\'aprÃ¨s', 'lefaso', 'titre']
        if any(indicator in answer_lower for indicator in source_indicators):
            score += 1.0
        
        return min(5.0, score)
    
    def evaluate_single_question(self, test_case: Dict, use_local_llm: bool = False) -> Dict:
        """
        Ã‰valuation d'une seule question
        
        Args:
            test_case: Dictionnaire avec question, expected_answer, keywords
            use_local_llm: Utiliser LLM local ou HuggingFace
        
        Returns:
            RÃ©sultats de l'Ã©valuation
        """
        question = test_case['question']
        expected_answer = test_case['expected_answer']
        keywords = test_case.get('keywords', [])
        
        print(f"\nâ“ Question: {question}")
        
        # Obtenir la rÃ©ponse
        start_time = time.time()
        result = self.rag.answer_question(
            query=question,
            use_local_llm=use_local_llm,
            verbose=False
        )
        response_time = time.time() - start_time
        
        # Calculer les mÃ©triques
        retrieval_precision = self.calculate_retrieval_precision(
            result['sources'],
            keywords
        )
        
        answer_relevance = self.calculate_answer_relevance(
            result['answer'],
            expected_answer,
            question
        )
        
        evaluation = {
            'question': question,
            'answer': result['answer'],
            'expected_answer': expected_answer,
            'retrieval_precision': retrieval_precision,
            'answer_relevance': answer_relevance,
            'response_time': response_time,
            'num_sources': len(result['sources']),
            'sources': result['sources']
        }
        
        print(f"  âœ… PrÃ©cision Retrieval: {retrieval_precision*100:.1f}%")
        print(f"  âœ… Pertinence RÃ©ponse: {answer_relevance:.1f}/5")
        print(f"  â±ï¸ Temps: {response_time:.2f}s")
        
        return evaluation
    
    def run_full_evaluation(self, use_local_llm: bool = False) -> Dict:
        """
        Ã‰valuation complÃ¨te avec toutes les questions test
        
        Returns:
            RÃ©sultats agrÃ©gÃ©s + dÃ©tails
        """
        print("="*60)
        print("ðŸ”¬ Ã‰VALUATION DU SYSTÃˆME RAG")
        print("="*60)
        
        # Charger les questions test
        with open(self.test_file, 'r', encoding='utf-8') as f:
            test_cases = json.load(f)
        
        print(f"\nðŸ“‹ {len(test_cases)} questions test chargÃ©es\n")
        
        # Ã‰valuer chaque question
        results = []
        for i, test_case in enumerate(test_cases, 1):
            print(f"\n[{i}/{len(test_cases)}]")
            result = self.evaluate_single_question(test_case, use_local_llm)
            results.append(result)
            time.sleep(0.5)  # Pause pour Ã©viter rate limiting
        
        # Calcul des mÃ©triques agrÃ©gÃ©es
        avg_retrieval_precision = np.mean([r['retrieval_precision'] for r in results])
        avg_answer_relevance = np.mean([r['answer_relevance'] for r in results])
        avg_response_time = np.mean([r['response_time'] for r in results])
        
        # Distribution des scores
        relevance_scores = [r['answer_relevance'] for r in results]
        score_distribution = {
            'excellent (4-5)': sum(1 for s in relevance_scores if s >= 4),
            'bon (3-4)': sum(1 for s in relevance_scores if 3 <= s < 4),
            'moyen (2-3)': sum(1 for s in relevance_scores if 2 <= s < 3),
            'faible (<2)': sum(1 for s in relevance_scores if s < 2)
        }
        
        # RÃ©sultats finaux
        final_results = {
            'metadata': {
                'evaluation_date': datetime.now().isoformat(),
                'total_questions': len(test_cases),
                'llm_used': 'Local (Ollama)' if use_local_llm else 'HuggingFace API'
            },
            'aggregate_metrics': {
                'avg_retrieval_precision': round(avg_retrieval_precision, 3),
                'avg_retrieval_precision_percent': round(avg_retrieval_precision * 100, 1),
                'avg_answer_relevance': round(avg_answer_relevance, 2),
                'avg_response_time': round(avg_response_time, 2),
                'score_distribution': score_distribution
            },
            'detailed_results': results
        }
        
        # Affichage du rapport
        print("\n" + "="*60)
        print("ðŸ“Š RÃ‰SULTATS D'Ã‰VALUATION")
        print("="*60)
        print(f"\nðŸŽ¯ PrÃ©cision Retrieval (moyenne): {avg_retrieval_precision*100:.1f}%")
        print(f"ðŸ’¬ Pertinence RÃ©ponse (moyenne): {avg_answer_relevance:.2f}/5")
        print(f"â±ï¸ Temps RÃ©ponse (moyenne): {avg_response_time:.2f}s")
        
        print(f"\nðŸ“ˆ Distribution des scores:")
        for category, count in score_distribution.items():
            print(f"  - {category}: {count} questions ({count/len(test_cases)*100:.1f}%)")
        
        print("\n" + "="*60)
        
        return final_results
    
    def save_results(self, results: Dict, output_file: str):
        """Sauvegarde des rÃ©sultats en JSON"""
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"\nðŸ’¾ RÃ©sultats sauvegardÃ©s: {output_file}")
    
    def generate_report(self, results: Dict, output_file: str):
        """GÃ©nÃ©ration d'un rapport markdown"""
        report = f"""# Rapport d'Ã‰valuation - Culture BurkinabÃ¨ RAG

**Date:** {results['metadata']['evaluation_date']}  
**LLM utilisÃ©:** {results['metadata']['llm_used']}  
**Nombre de questions test:** {results['metadata']['total_questions']}

---

## ðŸ“Š MÃ©triques Globales

| MÃ©trique | Valeur |
|----------|--------|
| **PrÃ©cision Retrieval** | {results['aggregate_metrics']['avg_retrieval_precision_percent']}% |
| **Pertinence RÃ©ponse** | {results['aggregate_metrics']['avg_answer_relevance']}/5 |
| **Temps de RÃ©ponse** | {results['aggregate_metrics']['avg_response_time']}s |

## ðŸ“ˆ Distribution des Scores de Pertinence

"""
        for category, count in results['aggregate_metrics']['score_distribution'].items():
            percent = count / results['metadata']['total_questions'] * 100
            report += f"- **{category}**: {count} questions ({percent:.1f}%)\n"
        
        report += "\n---\n\n## ðŸ“ RÃ©sultats DÃ©taillÃ©s\n\n"
        
        for i, result in enumerate(results['detailed_results'], 1):
            report += f"""### Question {i}

**Question:** {result['question']}

**RÃ©ponse gÃ©nÃ©rÃ©e:**  
{result['answer']}

**MÃ©triques:**
- PrÃ©cision Retrieval: {result['retrieval_precision']*100:.1f}%
- Pertinence: {result['answer_relevance']:.1f}/5
- Temps: {result['response_time']:.2f}s
- Sources: {result['num_sources']}

---

"""
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"ðŸ“„ Rapport markdown gÃ©nÃ©rÃ©: {output_file}")


def create_test_questions():
    """CrÃ©ation des 20 questions test avec rÃ©ponses attendues"""
    
    test_questions = [
        {
            "question": "Quels sont les principaux festivals culturels au Burkina Faso?",
            "expected_answer": "Les principaux festivals incluent les REMA (Rencontres Musicales Africaines), le FESPACO (festival de cinÃ©ma), et divers festivals de musique et d'arts.",
            "keywords": ["REMA", "festival", "FESPACO", "musique", "culture"]
        },
        {
            "question": "Qui est Alif Naaba?",
            "expected_answer": "Alif Naaba est un artiste burkinabÃ¨, initiateur du projet 'Nos voix pour la paix' qui rassemble plusieurs artistes pour promouvoir la cohÃ©sion sociale.",
            "keywords": ["Alif Naaba", "artiste", "paix", "musique"]
        },
        {
            "question": "Qu'est-ce que le BBDA?",
            "expected_answer": "Le BBDA (Bureau BurkinabÃ¨ du Droit d'Auteur) est une institution qui gÃ¨re les droits collectifs des artistes au Burkina Faso.",
            "keywords": ["BBDA", "droits d'auteur", "artistes", "gestion"]
        },
        {
            "question": "Que sont les REMA?",
            "expected_answer": "Les REMA (Rencontres Musicales Africaines) sont un festival majeur de musique qui se tient Ã  Ouagadougou et rassemble des artistes africains.",
            "keywords": ["REMA", "musique", "festival", "Ouagadougou", "africain"]
        },
        {
            "question": "Quel est le rÃ´le de la culture dans la cohÃ©sion sociale au Burkina Faso?",
            "expected_answer": "La culture, notamment la musique et les festivals, joue un rÃ´le de ciment social et contribue Ã  promouvoir la paix et la cohÃ©sion entre les diffÃ©rentes communautÃ©s.",
            "keywords": ["culture", "cohÃ©sion", "paix", "social", "musique"]
        },
        {
            "question": "Qui a visitÃ© le BBDA rÃ©cemment?",
            "expected_answer": "Le Premier ministre a effectuÃ© une visite historique au BBDA, une premiÃ¨re pour cette institution.",
            "keywords": ["Premier ministre", "BBDA", "visite", "historique"]
        },
        {
            "question": "Quels artistes ont participÃ© au projet 'Nos voix pour la paix'?",
            "expected_answer": "9 artistes ont participÃ©: Alif Naaba, Floby, Amzy, Kawayoto, Fleur, Flora ParÃ©, ATT et Sissao, Sydyr.",
            "keywords": ["artistes", "Nos voix pour la paix", "Floby", "Alif Naaba"]
        },
        {
            "question": "Quelle est la tournÃ©e prÃ©vue pour 'Nos voix pour la paix'?",
            "expected_answer": "Une tournÃ©e est prÃ©vue dans 8 villes: Ouagadougou, Kaya, Tenkodogo, PÃ´, Gaoua, Koudougou, Ouahigouya et Bobo Dioulasso.",
            "keywords": ["tournÃ©e", "villes", "Ouagadougou", "Bobo"]
        },
        {
            "question": "Quel message le ministre de la culture a-t-il transmis aux artistes?",
            "expected_answer": "Le ministre encourage les artistes Ã  rechercher l'excellence, Ã  crÃ©er des Å“uvres originales et de qualitÃ©, et Ã  conquÃ©rir le monde au-delÃ  des frontiÃ¨res du Burkina Faso.",
            "keywords": ["ministre", "excellence", "artistes", "qualitÃ©"]
        },
        {
            "question": "Comment les artistes peuvent-ils contribuer Ã  la sÃ©curitÃ© nationale?",
            "expected_answer": "Les artistes peuvent galvaniser les combattants et le peuple par leurs crÃ©ations et leur engagement dans le combat pour la souverainetÃ©.",
            "keywords": ["artistes", "sÃ©curitÃ©", "engagement", "souverainetÃ©"]
        },
        {
            "question": "Quel est le rÃ´le de l'Union europÃ©enne dans les projets culturels?",
            "expected_answer": "L'Union europÃ©enne soutient des projets culturels comme 'Nos voix pour la paix' pour contribuer au retour de la paix et au renforcement de la cohÃ©sion sociale.",
            "keywords": ["Union europÃ©enne", "soutien", "paix", "culture"]
        },
        {
            "question": "Quelles langues sont utilisÃ©es dans le titre 'Nos voix pour la paix'?",
            "expected_answer": "Plusieurs langues nationales sont chantÃ©es dans ce titre afin que le message soit entendu par la majoritÃ© de la population.",
            "keywords": ["langues", "nationales", "message", "population"]
        },
        {
            "question": "Quand se tient la 6e Ã©dition des REMA?",
            "expected_answer": "La 6e Ã©dition des REMA se tient du 19 au 21 octobre 2023.",
            "keywords": ["REMA", "octobre 2023", "Ã©dition"]
        },
        {
            "question": "Quelle est l'importance du BBDA pour les artistes?",
            "expected_answer": "Le BBDA permet aux artistes de vivre dignement de leur art en gÃ©rant le recouvrement de leurs droits d'auteur.",
            "keywords": ["BBDA", "artistes", "droits", "recouvrement"]
        },
        {
            "question": "Quels thÃ¨mes sont abordÃ©s durant la tournÃ©e 'Nos voix pour la paix'?",
            "expected_answer": "Les thÃ¨mes incluent la paix, la solidaritÃ©, la dÃ©mocratie, la protection de l'environnement, la justice et l'Ã©galitÃ©.",
            "keywords": ["paix", "solidaritÃ©", "dÃ©mocratie", "justice", "Ã©galitÃ©"]
        },
        {
            "question": "Quelle est la vision du ministre pour les artistes burkinabÃ¨?",
            "expected_answer": "Le ministre souhaite que les artistes burkinabÃ¨ franchissent les frontiÃ¨res et que leurs Å“uvres soient reconnues mondialement.",
            "keywords": ["ministre", "artistes", "frontiÃ¨res", "mondial"]
        },
        {
            "question": "Comment la musique peut-elle changer les comportements?",
            "expected_answer": "Selon Alif Naaba, la musique a la capacitÃ© d'apporter un changement de comportement et peut contribuer Ã  apaiser les situations difficiles.",
            "keywords": ["musique", "comportement", "changement", "Alif Naaba"]
        },
        {
            "question": "Qu'est-ce qui accompagne la tournÃ©e musicale?",
            "expected_answer": "Un tournoi de Maracana accompagne la tournÃ©e, dÃ©butant le jour de l'ouverture des REMA.",
            "keywords": ["tournoi", "Maracana", "REMA", "sport"]
        },
        {
            "question": "Quelle est l'importance de l'art pour la paix selon les participants?",
            "expected_answer": "L'art, particuliÃ¨rement la culture, est considÃ©rÃ© comme le ciment qui contribue Ã  apporter la paix, toutes les guerres se terminant sur la table de la nÃ©gociation.",
            "keywords": ["art", "paix", "culture", "nÃ©gociation"]
        },
        {
            "question": "Quel est le message portÃ© par 'Nos voix pour la paix'?",
            "expected_answer": "Le message vise Ã  promouvoir la paix, la cohÃ©sion sociale et l'espoir au Burkina Faso Ã  travers la musique.",
            "keywords": ["message", "paix", "cohÃ©sion", "espoir", "musique"]
        }
    ]
    
    return test_questions


if __name__ == "__main__":
    # CrÃ©er les questions test
    print("ðŸ“ CrÃ©ation des questions test...")
    test_questions = create_test_questions()
    
    # Sauvegarder
    with open("evaluation/test_questions.json", 'w', encoding='utf-8') as f:
        json.dump(test_questions, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… {len(test_questions)} questions test crÃ©Ã©es")
    
    # Initialiser le RAG
    print("\nðŸš€ Initialisation du pipeline RAG...")
    rag = CultureRAGPipeline(
        corpus_file="data/processed/corpus_cleaned.json"
    )
    
    # CrÃ©er l'Ã©valuateur
    evaluator = RAGEvaluator(rag, "evaluation/test_questions.json")
    
    # Lancer l'Ã©valuation
    results = evaluator.run_full_evaluation(use_local_llm=False)
    
    # Sauvegarder les rÃ©sultats
    evaluator.save_results(results, "evaluation/results.json")
    evaluator.generate_report(results, "evaluation/RAPPORT_EVALUATION.md")
    
    print("\nâœ… Ã‰valuation terminÃ©e!")